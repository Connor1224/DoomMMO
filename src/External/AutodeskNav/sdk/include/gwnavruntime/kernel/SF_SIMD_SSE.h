/*
* Copyright 2012 Autodesk, Inc. All rights reserved.
* Use of this software is subject to the terms of the Autodesk license agreement and any attachments or Appendices thereto provided at the time of installation or download,
* or which otherwise accompanies this software in either electronic or hard copy form, or which is signed by you and accepted by Autodesk.
*/

/**************************************************************************

Filename    :   KY_SIMD_SSE.h
Content     :   SIMD instruction set(s) for SSE.
Created     :   Dec 2010
Authors     :   Bart Muzzin

**************************************************************************/

#ifndef INC_KY_SF_SIMD_SSE_H
#define INC_KY_SF_SIMD_SSE_H
#pragma once

#if defined(KY_ENABLE_SIMD) && defined(KY_CPU_SSE)

#include <emmintrin.h>

#if defined(_MSC_VER)
    // MSVC style alignment.
    #pragma warning (disable : 4324) // warning C4324: 'struct' : structure was padded due to __declspec(align())
    #define KY_SIMD_ALIGN(x)  __declspec(align(16)) x
#elif defined(__GNUC__)
    // GCC style alignment
    #define KY_SIMD_ALIGN(x) x __attribute__((aligned(16)))
#else
    #error Unexpected compiler supporting SSE instructions.
#endif

namespace Kaim { namespace SIMD { 

typedef __m128 Vector4f;
typedef __m128i Vector4i;

// Separated, because there may be multiple instructions sets (but not currently).
namespace SSE { 

class InstructionSet
{
public:
    // Loads a value from aligned memory, and returns it.
    static Vector4f LoadAligned( const float * p )
    {
        return _mm_load_ps(p);
    }

    // Loads a value from aligned memory, and returns it.
    static Vector4i LoadAligned( const Vector4i * p )
    {
        return _mm_loadu_si128(p);
    }

    // Stores a value to aligned memory.
    static void StoreAligned( float * p, Vector4f v )
    {
        return _mm_store_ps(p, v);
    }

    // Stores a values to aligned memory, without using the cache.
    static void StreamAligned( Vector4i * p, Vector4i v )
    {
        return _mm_stream_si128(p, v);
    }

    // Creates a 4 single-precision floating point constant from 4 unsigned integers.
    template< unsigned int i0, unsigned int i1, unsigned int i2, unsigned int i3 >
    static Vector4f Constant( )
    {
#if defined(_MSC_VER)
        // When initializing unions which contain arrays (which __m128i is), the the initializers are cast to the first member in the union.
        static Vector4i v = { 
            ((i0&0x000000FF) >> 0 ), ((i0&0x0000FF00) >> 8), ((i0&0x00FF0000) >> 16), ((i0&0xFF000000) >> 24), 
            ((i1&0x000000FF) >> 0 ), ((i1&0x0000FF00) >> 8), ((i1&0x00FF0000) >> 16), ((i1&0xFF000000) >> 24), 
            ((i2&0x000000FF) >> 0 ), ((i2&0x0000FF00) >> 8), ((i2&0x00FF0000) >> 16), ((i2&0xFF000000) >> 24), 
            ((i3&0x000000FF) >> 0 ), ((i3&0x0000FF00) >> 8), ((i3&0x00FF0000) >> 16), ((i3&0xFF000000) >> 24) };
#else
        static const __m128i v = _mm_set_epi32(i3, i2, i1, i0);
#endif
        return *(Vector4f*)&v;
    }

    // Sets 8 16-bit integer values in the register to the input.
    static Vector4i Set1(UInt16 v)
    {
        return _mm_set1_epi16(v);
    }

    // Splats 1 value to each word.
    template< int word >
    static Vector4f Splat(Vector4f r0)
    {
        return Shuffle<word,word,word,word>(r0,r0);
    }

    // Takes two registers, selects two elements from the first, and two from the second.
    // all template arguments are in the range 0-3, f0 and f1 refer to the elements in r0,
    // f2 and f3 refer to the elements in r1.
    template <int f0, int f1, int f2, int f3>
    static Vector4f Shuffle( Vector4f r0, Vector4f r1 )
    {
        return _mm_shuffle_ps(r0, r1, _MM_SHUFFLE(f3, f2, f1, f0));
    }

    // Interleaves the two low components of r0 and r1.
    static Vector4f UnpackLo( Vector4f r0, Vector4f r1 )
    {
        return _mm_unpacklo_ps(r0, r1);
    }

    // Interleaves the two high components of r0 and r1.
    static Vector4f UnpackHi( Vector4f r0, Vector4f r1 )
    {
        return _mm_unpackhi_ps(r0, r1);
    }

    // Multiplies two input registers and returns the result.
    static Vector4f Multiply( Vector4f r0, Vector4f r1 )
    {
        return _mm_mul_ps(r0, r1);
    }

    // Divides r0 by r1, and returns the result.
    static Vector4f Divide( Vector4f r0, Vector4f r1 )
    {
        return _mm_div_ps(r0, r1);
    }

    // Takes the dot product of the two input registers (first three elements)
    // and returns the result in every component
    static Vector4f Dot3( Vector4f r0, Vector4f r1 )
    {
        Vector4f r = Multiply( r0, r1 );
        return Add( Add( Splat<0>(r), Splat<1>(r)), Splat<2>(r));
    }

    // Adds to input registers and returns the result.
    static Vector4f Add( Vector4f r0, Vector4f r1 )
    {
        return _mm_add_ps(r0, r1);
    }

    // Adds 16-bit integer elements in two registers together
    static Vector4i Add16( Vector4i r0, Vector4i r1 )
    {
        return _mm_add_epi16(r0, r1);
    }

    // Multiplies r0 and r1 then adds r2.
    static Vector4f MultiplyAdd( Vector4f r0, Vector4f r1, Vector4f r2 )
    {
        return Add( Multiply(r0, r1), r2 );
    }

    // Computes minimum component-wise values between r0 and r1.
    static Vector4f Min( Vector4f r0, Vector4f r1 )
    {
        return _mm_min_ps(r0, r1);
    }

    // Computes maximum component-wise values between r0 and r1.
    static Vector4f Max( Vector4f r0, Vector4f r1 )
    {
        return _mm_max_ps(r0, r1);
    }

    // Returns the bitwise and of the two input registers.
    static Vector4f And( Vector4f r0, Vector4f r1 )
    {
        return _mm_and_ps( r0, r1 );
    }

    // Element-wise comparison of two registers, returns r0.i >= r1.i ? 0xFFFFFFFF : 0;
    static Vector4f CompareGE( Vector4f r0, Vector4f r1 )
    {
        return _mm_cmpge_ps(r0, r1);
    }

    // Element-wise comparison of two registers (equal), returns true if any of the elements passes the comparison.
    static bool CompareEQ_Any( Vector4f r0, Vector4f r1 )
    {
        Vector4f result = _mm_cmpneq_ps(r0,r1);
        return (_mm_movemask_ps(result) & 0xF) != 0xF;
    }

    // Element-wise comparison of two registers, returns true if all of the elements passes the comparison.
    static bool CompareEQ_All( Vector4f r0, Vector4f r1 )
    {
        Vector4f result = _mm_cmpeq_ps(r0,r1);
        return (_mm_movemask_ps(result) & 0xF) == 0xF;
    }

    // Gathers the MSB (sign) bit of each element in r0, and returns them in the LSB
    // four bits of the return. The rest of the return bits are zero.
    static int MoveMask( Vector4f r0 )
    {
        return _mm_movemask_ps(r0);
    }

    // Computes the reciprocal square root estimate of each input element.
    static Vector4f ReciprocalSqrt( Vector4f r0 )
    {
        return _mm_rsqrt_ps(r0);
    }

    // Computes the reciprocal estimate of each input element.
    static Vector4f Reciprocal( Vector4f r0 )
    {
        return _mm_rcp_ps(r0);
    }

    // Computes the element-wise difference between r0 and r1.
    static Vector4f Subtract( Vector4f r0, Vector4f r1 )
    {
        return _mm_sub_ps(r0, r1);
    }

    // Computes the element-wise absolute value of r0.
    static Vector4f Abs( Vector4f r0 )
    {
        Vector4f nosignbit = Constant<0x7FFFFFFF, 0x7FFFFFFF, 0x7FFFFFFF, 0x7FFFFFFF>();
        return And( r0, nosignbit );
    }

    static Vector4f Select(Vector4f r0, Vector4f r1, Vector4f mask)
    {
        return _mm_xor_ps( r0, _mm_and_ps( mask, _mm_xor_ps( r1, r0 ) ) );
    }

    // Prefetches a single cache line of the given address.
    static void Prefetch(const void * p, int offset)
    {
        // Loads it only into the L2 cache, not L1 cache.
        return _mm_prefetch( (const char*)p + offset, _MM_HINT_T1 );
    }

    // Prefetches an entire object (does multiple prefetches, if the class is too large
    // for a single cache line.
    template<class T>
    static void PrefetchObj( const T * obj )
    {
        // On Win32, we will assume cache line size is 32 bytes. It should not be less than this,
        // if it is greater, we will wasting some prefetch instructions, however, that is better
        // than branching on the cache line size.
        static const int CACHE_LINE_SIZE = 32;
        switch((sizeof(T)-1)/32)
        {
            // Only handles objects up to 256 bytes.
            default:
            case 7: Prefetch(obj, 7*CACHE_LINE_SIZE);
            case 6: Prefetch(obj, 6*CACHE_LINE_SIZE);
            case 5: Prefetch(obj, 5*CACHE_LINE_SIZE);
            case 4: Prefetch(obj, 4*CACHE_LINE_SIZE);
            case 3: Prefetch(obj, 3*CACHE_LINE_SIZE);
            case 2: Prefetch(obj, 2*CACHE_LINE_SIZE);
            case 1: Prefetch(obj, 1*CACHE_LINE_SIZE);
            case 0: Prefetch(obj, 0*CACHE_LINE_SIZE);
        }
    }
};

} // SSE

// Define the default instruction set.
typedef SSE::InstructionSet IS;

}} // Kaim::SIMD

#endif // KY_ENABLE_SIMD && KY_OS_WIN32

#endif // INC_KY_SF_SIMD_WIN32_H
